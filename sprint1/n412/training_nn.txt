신경망 훈련 과정
          ┌ 1. 순전파 : 가중합 연산
iteration │ 2. 결과 출력
          │ 3. 손실함수로 손실 계산               
          └ 4. 역전파 : 경사하강법으로 가중치 갱신 
            5. 반복

=======================================================

1. 순전파
- 가중합 연산을 거쳐 출력층에서 값을 출력하는 과정
- 가중합 연산 -> 활성화 함수

=======================================================

2. 손실 함수
- 출력값과 타겟값을 손실 함수에 넣어 손실 계산

=========================================================

3. 역전파
- 손실 함수에서 얻은 손실을 최소화하는 방향(경사 하강법)으로 가중치 갱신

3-1) 경사 하강법
- 손실함수의 미분값을 기존 가중치에서 빼주어 새로운 가중치 계산
- θ=θ−η∇_θJ(θ)

3-2) 편미분

3-3) 연쇄법칙

==========================================================

4. 옵티마이저
- 경사하강법의 종류
- GD, SGD, Mini-Batch, ...

4-1) GD(Batch GD)
- 모든 데이터에 대한 손실함수의 기울기 계산 후 가중치 갱신
- epoch = iteration

4-2) SGD
- 선택한 데이터 1개에 대해 기울기 계산 후 갱신
- 모든 데이터에 대해 수행
- epoch << iteration

4-3) Mini-Batch
- 여러 데이터(배치)에 대해 기울기 계산 후 평균 후 갱신
- epoch < iteration

4-4) 배치
- SGD : 1개로
- Mini-Batch : N개로
    - 보통 2의 배수로 설정
- 배치 사이즈 X iteration = 전체 데이터 크기